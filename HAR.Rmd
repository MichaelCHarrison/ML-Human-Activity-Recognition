---
title: "Human Activity Recognition Predictive Analysis"
output: html_notebook
---

*Problem Description*

Wearable technologies (such as Fitbit, Nike FuelBand and Garvmin Vivosmart products) have allowed for the widespread collection of data relating to physical activity. While the focus of these devices is largely on quantifying and tracking the amount of activity, the data collected carries the potential to assess not only quantifiable measures but qualitative as well. Human Activity Recognition (HAR) has hained increasing attention in the research community for the development of potential applications in context-aware systems. 

Using the dataset from Ugulino et al.'s "Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements", in which subjects performed barbell lifts correctly and incorrectly to establish 5 different classes of activity, I will use machine learning based classifer to predict the class of acitivy for the data set.

*Provided Data*
```{r, warning=FALSE, message=FALSE}
library(caret)
library(data.table)

training <- fread("pml-training.csv")
testing <- fread("pml-testing.csv")
dim(training)
```



- Data Constraints
The 19,622 observations of 160 variables contains many variables unnecessary in model building, namely the first 7 columns pertaining to observation number, subject name, timestamps, and window variable. Additionally, derived column variables containing missing data or NA values (kurtosis, skewness, max, min, variance, standard deviation, amplitude, and average of sensors) will be removed, preserving only measurements from belt, arm, formarm, and dumbbell. Finally, column types need to be converted from character class to numeric for modeling purposes.

```{r, cache=TRUE}
#remove NA columns; max, min, variance, sd, amplitude, average
trainingPrime <- t(na.omit(t(training)))
#remove observation number, subject name, timestamps
trainingPrime <- trainingPrime[, -c(1:7)]
#remove kurtosis, skewness, yaw column variables
toDrop <- c("^kurtosis*","^skewness*","yaw")
trainingPrime <- trainingPrime[, -grep(paste(toDrop, collapse = "|"),
                                       colnames(trainingPrime))]
#transform matrix to data.table
trainingPrime <- as.data.table(trainingPrime)
#Convert character class values to numeric
trainingPrime[,1:48] <- trainingPrime[, lapply(trainingPrime[,1:48], as.numeric)]
trainingPrime$classe <- as.factor(trainingPrime$classe)
dim(trainingPrime)
```

*Analyze Data*

Dataset now contains 48 predictors (numeric variables), 1 outcome (factor variable). 
```{r}
summary(trainingPrime$classe)
```
```{r, warning=FALSE}
ggplot(trainingPrime, aes(classe)) + geom_histogram(stat="count")
```

```{r}
featurePlot(x = trainingPrime[,1:12], y = trainingPrime[,49], plot="pairs")
```

        

```{r}
library(corrplot)
corrplot(cor(trainingPrime[,1:12]), method="color", type="upper")
```

~Sampling
```{r}
inTrain <- createDataPartition(y=trainingPrime$classe,
                               p=.75, list=FALSE)
training1 <- trainingPrime[inTrain,]
testing1 <- trainingPrime[-inTrain,]
```

*Evaluate Algorithm*

For the purposes of this classification analysis, I will use randomForest. The baseline will be established with an mtry value of the rounded square root of the number of predictors.

```{r}
x <- training1[,1:48]
y <- training1$classe
seed <- 170418
```

```{r}
#Configures parallel processing
library(parallel)
library(doParallel)
library(randomForest)

start.time <- Sys.time()
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(seed)
fitRF <- train(x, y, data=training1, 
               method="rf", 
               metric = "Accuracy",   
               trControl = fitControl,
               tuneGrid = expand.grid(mtry=round(sqrt(ncol(x)))))

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF <- end.time - start.time
fitRF$results
```

*Improve Results*
To improve the accuracy of the randomForest, I'll use the tuneRF function to optimize the mtry value.


```{r}
start.time <- Sys.time()
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

set.seed(seed)
optmtryRF2 <- tuneRF(x, y, 
                  stepFactor = 1.5, 
                  improve = 1e-5, ntreeTry = 500)

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF2 <- end.time - start.time
optmtryRF2
```

Result shows that a mtry = 6 is optimal for this data set.

```{r}
start.time <- Sys.time()
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = round(sqrt(ncol(x))))

#tune the algorithm for ntrees
fitList <- list()
for(ntree in c(300, 400, 500, 600, 700)){
        set.seed(seed)
        fitRF <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList[[key]] <- fitRF
}

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time
```



#RF, mtry = 7#
```{r}
#Configur parallel processing
start.time <- Sys.time()
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(seed)
fitRF1 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneGrid = expand.grid(mtry=round(sqrt(ncol(x)))))

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF1 <- end.time - start.time #Time difference of 8.76054 mins
fitRF1
```


#Resample Stats#
```{r}
fitRF1$resample
```


#Confustion Matrix#
```{r}
confusionMatrix(fitRF1)
```


#Applied Tuning#
```{r}
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#Recommended default control features
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(1704111)
fitRF3 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneGrid = expand.grid(mtry=6))

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF3 <- end.time - start.time
fitRF3
```








##Scrapped Scripts##
```{r}
#Configur parallel processing
start.time <- Sys.time()
library(parallel)
library(doParallel)
library(randomForest)

cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#search = "random"
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           search = "random",
                           allowParallel = TRUE)

set.seed(1704111)
fitRF2 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneLength = 15)

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF2 <- end.time - start.time
fitRF2
```

```{r}
start.time <- Sys.time()
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

inTrain2 <- createDataPartition(y=trainingPrime$classe,
                               p=.75, list=FALSE)
training2 <- trainingPrime[inTrain2,]
testing2 <- trainingPrime[-inTrain2,]

gbmGrid <- expand.grid(shrinkage = .1,
                       n.trees = (1:30)*50,
                       interaction.depth = c(1,5,9),
                       n.minobsinnode = 20)

fitControl2 <- trainControl(method = "cv",
                            number = 10,
                            allowParallel = TRUE)
set.seed(1704112)
fit2 <- train(classe~., data=training2,
              method="gbm", trControl = fitControl2,
              verbose=FALSE, tuneGrid=gbmGrid)
stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.taken <- end.time - start.time
fit2

```


*Applying randomForest model to testing set*
```{r}
pred1 <- predict(fit1, testing1)
testing1$predRight <- pred1 == testing1$classe
table(pred1, testing1$classe)
```
```{r}
sum(testing1$predRight)/length(testing1$classe)
```

