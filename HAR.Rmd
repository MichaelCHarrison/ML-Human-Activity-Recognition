Human Activity Recognition

*Problem Description*


*Provided Data*
```{r, warning=FALSE}
library(caret)
library(data.table)

training <- fread("pml-training.csv")
testing <- fread("pml-testing.csv")
```

-Constraints
        - 160 variables: many NAs
        - First 7 unrelated to question
        - Many variables in data set are derived variables: kurtosis, skewness,
        max, min, var, sd, amplitude, avg
-Present working dataset


*Tidying Data*
```{r, cache=TRUE}
trainingPrime <- t(na.omit(t(training)))
trainingPrime <- trainingPrime[, -c(1:7)]
toDrop <- c("^kurtosis*","^skewness*","yaw")
trainingPrime <- trainingPrime[, -grep(paste(toDrop, collapse = "|"),
                                       colnames(trainingPrime))]
trainingPrime <- as.data.table(trainingPrime)
```


```{r}
trainingPrime[,1:48] <- trainingPrime[, lapply(trainingPrime[,1:48], as.numeric)]
trainingPrime$classe <- as.factor(trainingPrime$classe)
dim(trainingPrime)
```

*Analyze Data*
- Summarize
        - Data Structure
        - Data Distributions
- Visualize
        - Atrribute Histogram
        - Pairwise scatter plot

*Prepare Data*
- Formatting
- Cleaning
- Sampling

#Sampling#
```{r}
inTrain <- createDataPartition(y=trainingPrime$classe,
                               p=.75, list=FALSE)
training1 <- trainingPrime[inTrain,]
testing1 <- trainingPrime[-inTrain,]
```

*Evaluate Algorithm*

- Select Algorithm
        - Interpret and report results


#RF, mtry = 7#
```{r}
#Configur parallel processing
start.time <- Sys.time()
library(parallel)
library(doParallel)
library(randomForest)

cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

####################Run default first#############################
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(1704111)
fitRF1 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneGrid = expand.grid(mtry=7))

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF1 <- end.time - start.time #Time difference of 8.76054 mins
fitRF1
```


#Resample Stats#
```{r}
fitRF1$resample
```


#Confustion Matrix#
```{r}
confusionMatrix(fitRF1)
```


*Improve Results*
- Algorithm Tuning
        - Using the tunRF function of randomForest to optimize mtry value
        
        
        
#Tuning#
```{r}
x <- training1[,1:48]
y <- training1$classe
set.seed(1704111)
time.start <- Sys.time()
optmtry <- tuneRF(x, y, 
                  stepFactor = 1.5, 
                  improve = 1e-5, ntreeTry = 500)
time.end <- Sys.time()
time.takenRF2 <- time.end - time.start
optmtry
```

#Applied Tuning#
```{r}
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#Recommended default control features
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(1704111)
fitRF3 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneGrid = expand.grid(mtry=6))

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF3 <- end.time - start.time
fitRF3
```








##Scrapped Scripts##
```{r}
#Configur parallel processing
start.time <- Sys.time()
library(parallel)
library(doParallel)
library(randomForest)

cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

#search = "random"
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           search = "random",
                           allowParallel = TRUE)

set.seed(1704111)
fitRF2 <- train(classe~., data=training1, 
                method="rf", 
                metric = "Accuracy", 
                trControl = fitControl, 
                tuneLength = 15)

stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.takenRF2 <- end.time - start.time
fitRF2
```

```{r}
start.time <- Sys.time()
library(parallel)
library(doParallel)
cluster <- makeCluster(detectCores()-1)
registerDoParallel(cluster)

inTrain2 <- createDataPartition(y=trainingPrime$classe,
                               p=.75, list=FALSE)
training2 <- trainingPrime[inTrain2,]
testing2 <- trainingPrime[-inTrain2,]

gbmGrid <- expand.grid(shrinkage = .1,
                       n.trees = (1:30)*50,
                       interaction.depth = c(1,5,9),
                       n.minobsinnode = 20)

fitControl2 <- trainControl(method = "cv",
                            number = 10,
                            allowParallel = TRUE)
set.seed(1704112)
fit2 <- train(classe~., data=training2,
              method="gbm", trControl = fitControl2,
              verbose=FALSE, tuneGrid=gbmGrid)
stopCluster(cluster)
registerDoSEQ()
end.time <- Sys.time()
time.taken <- end.time - start.time
fit2

```


*Applying randomForest model to testing set*
```{r}
pred1 <- predict(fit1, testing1)
testing1$predRight <- pred1 == testing1$classe
table(pred1, testing1$classe)
```
```{r}
sum(testing1$predRight)/length(testing1$classe)
```

