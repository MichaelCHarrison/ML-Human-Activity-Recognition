---
title: "Human Activity Recognition Predictive Analysis"
output: html_notebook
---

# Problem Description

This study will use the data from Ugulino et al.'s "Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements", in which subjects performed barbell lifts correctly and incorrectly to establish 5 different classes of activity. RandomForest will be the machine learning classifier used to predict the class of activity for the data set.

## Data
```{r, cache = TRUE, warning=FALSE, message=FALSE}
library(caret)
library(data.table)

training <- fread("pml-training.csv")
testing <- fread("pml-testing.csv")
dim(training)
```
```{r}
dim(testing)
```

### Data Constraints
The 19,622 observations of 160 variables contains many variables unnecessary in model building, namely: 
- the first 7 columns pertaining to observation number
- subject name
- timestamps 
- window variable  
Additionally, derived column variables containing missing data or NA values will be removed:
- kurtosis
- skewness
- max
- min
- variance
- standard deviation
- amplitude
- average of sensors  

Only measurements from the belt, arm, formarm, and dumbbell varables will be preserved and will be converted from character classes to numeric for modeling purposes.  

As the testing dataset only contains 20 instances of activity, the expectation of the prediciton model will be to correctly classify each instance in the correct class. 

```{r, cache=TRUE}
#remove NA columns; max, min, variance, sd, amplitude, average
trainingPrime <- t(na.omit(t(training)))

#remove observation number, subject name, timestamps
trainingPrime <- trainingPrime[, -c(1:7)]

#remove kurtosis, skewness, yaw column variables
toDrop <- c("^kurtosis*","^skewness*","yaw")
trainingPrime <- trainingPrime[, -grep(paste(toDrop, collapse = "|"),
                                       colnames(trainingPrime))]

#transform matrix to data.table
trainingPrime <- as.data.table(trainingPrime)
#Convert character class values to numeric; 49th variable (classe) set to factor
trainingPrime[,1:48] <- trainingPrime[, lapply(trainingPrime[,1:48], as.numeric)]
trainingPrime$classe <- as.factor(trainingPrime$classe)
dim(trainingPrime)
```

The training dataset now conatains 48 numeric predictors and 1 factor outcome. 

## Analyze Data

```{r, warning=FALSE, cache = TRUE}
library(ggplot2)
ggplot(trainingPrime, aes(classe)) + geom_histogram(stat="count")
```

```{r, cache = TRUE}
summary <- summary(trainingPrime$classe)
summary
```

The outcome classes are imbalanced and may need to balanced to improve prediction. The issue of outcome class imbalance will be revisited if the accuracy of the model does not meet the goal of 100% correct classification in the 20 instance testing dataset. Should the imbalance need to be corrected, the A classifer will be reduced to the mean of classes B through E.
        
## Evaluating RandomForest

To predict HAR, the caret and randomForest packages will be employed. The trainingPrime dataset will be partitioned to create training and validation sets 
```{r}
inTrain <- createDataPartition(y=trainingPrime$classe,
                               p=.70, list=FALSE)
training <- trainingPrime[inTrain,]
validation <- trainingPrime[-inTrain,]
```

```{r}
# Set predictors
x <- training1[,1:48]
y <- training1$classe
seed <- 170418
```



```{r}
#Configures parallel processing
library(parallel)
library(doParallel)

paraOn <- function(){
        cluster <- makeCluster(detectCores()-1)
        registerDoParallel(cluster)}

paraOff <- function(){
        stopCluster(cluster)
        registerDoSEQ()}
```

~Random Forest

```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(allowParallel = TRUE)

set.seed(seed)
fitRFDefault <- train(x, y, data = training1,
                      method = "rf", metric = "Accuracy",
                      trControl = fitControl)
paraOff()
end.time <- Sys.time()
time.takenRFDefault <- end.time - start.time #36.80987 minutes
fitRFDefault$results
```



```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(seed)
fitRF <- train(x, y, data=training1, 
               method="rf", 
               metric = "Accuracy",   
               trControl = fitControl,
               tuneGrid = expand.grid(mtry=round(sqrt(ncol(x)))))

paraOff()
end.time <- Sys.time()
time.takenRF <- end.time - start.time
fitRF$results
```

*Improve Results*
To improve the accuracy of the randomForest, I'll use the tuneRF function to optimize the mtry value.


```{r}
start.time <- Sys.time()
paraOn()

set.seed(seed)
optmtryRF2 <- tuneRF(x, y, 
                  stepFactor = 1.5, 
                  improve = 1e-4, ntreeTry = 500,
                  plot = TRUE)

paraOff()
end.time <- Sys.time()
time.takenRF2 <- end.time - start.time
optmtryRF2
```

The Out of Bag error as dependent on mtry seems to hold relatively constant between 6 and 9. As the rounded value of the square root of the number of columns comes out to 7, it doesn't appear that a changing the mtry value will return considerable change to the accuracy of the model.


Holding mtry constant, I will create a set of models with different ntree values to ascertain its ideal value.

```{r, cache = TRUE}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = round(sqrt(ncol(x))))

#tune the algorithm for ntrees
fitList <- list()
for(ntree in c(300, 400, 500, 600, 700)){
        set.seed(seed)
        fitRF <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList[[key]] <- fitRF
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time
results <- resamples(fitList)
summary(results)
```


```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = round(sqrt(ncol(x))))

#tune the algorithm for ntrees
fitList2 <- list()
for(ntree in c(1000, 1500, 2000)){
        set.seed(seed)
        fitRF <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList[[key]] <- fitRF
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time

results2 <- resamples(fitList)
summary(results2)
```



```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = c(6:9))

#tune the algorithm for ntrees
fitList3 <- list()
for(ntree in c(700, 2000)){
        set.seed(seed)
        fitRF3 <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList3[[key]] <- fitRF3
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time

results3 <- resamples(fitList3)
fitList3
```

