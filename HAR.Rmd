---
title: "Human Activity Recognition Predictive Analysis"
output: html_notebook
---

*Problem Description*

Wearable technologies (such as Fitbit, Nike FuelBand and Garvmin Vivosmart products) have allowed for the widespread collection of data relating to physical activity. While the focus of these devices is largely on quantifying and tracking the amount of activity, the data collected carries the potential to assess not only quantifiable measures but qualitative as well. Human Activity Recognition (HAR) has hained increasing attention in the research community for the development of potential applications in context-aware systems. 

Using the dataset from Ugulino et al.'s "Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements", in which subjects performed barbell lifts correctly and incorrectly to establish 5 different classes of activity, I will use machine learning based classifer to predict the class of acitivy for the data set.

*Provided Data*
```{r, warning=FALSE, message=FALSE}
library(caret)
library(data.table)

training <- fread("pml-training.csv")
testing <- fread("pml-testing.csv")
dim(training)
```



- Data Constraints
The 19,622 observations of 160 variables contains many variables unnecessary in model building, namely the first 7 columns pertaining to observation number, subject name, timestamps, and window variable. Additionally, derived column variables containing missing data or NA values (kurtosis, skewness, max, min, variance, standard deviation, amplitude, and average of sensors) will be removed, preserving only measurements from belt, arm, formarm, and dumbbell. Finally, column types need to be converted from character class to numeric for modeling purposes.

```{r, cache=TRUE}
#remove NA columns; max, min, variance, sd, amplitude, average
trainingPrime <- t(na.omit(t(training)))
#remove observation number, subject name, timestamps
trainingPrime <- trainingPrime[, -c(1:7)]
#remove kurtosis, skewness, yaw column variables
toDrop <- c("^kurtosis*","^skewness*","yaw")
trainingPrime <- trainingPrime[, -grep(paste(toDrop, collapse = "|"),
                                       colnames(trainingPrime))]
#transform matrix to data.table
trainingPrime <- as.data.table(trainingPrime)
#Convert character class values to numeric
trainingPrime[,1:48] <- trainingPrime[, lapply(trainingPrime[,1:48], as.numeric)]
trainingPrime$classe <- as.factor(trainingPrime$classe)
dim(trainingPrime)
```

*Analyze Data*

Dataset now contains 48 predictors (numeric variables), 1 outcome (factor variable). 
```{r, warning=FALSE}
ggplot(trainingPrime, aes(classe)) + geom_histogram(stat="count")
```

```{r}
summary(trainingPrime$classe)
```

        
~Sampling
```{r}
inTrain <- createDataPartition(y=trainingPrime$classe,
                               p=.75, list=FALSE)
training1 <- trainingPrime[inTrain,]
testing1 <- trainingPrime[-inTrain,]
```

*Evaluate Algorithm*

For the purposes of this classification analysis, I will use randomForest. The baseline will be established with an mtry value of the rounded square root of the number of predictors.

```{r}
x <- training1[,1:48]
y <- training1$classe
seed <- 170418
```

```{r}
#Configures parallel processing
library(parallel)
library(doParallel)

paraOn <- function(){
        cluster <- makeCluster(detectCores()-1)
        registerDoParallel(cluster)}

paraOff <- function(){
        stopCluster(cluster)
        registerDoSEQ()}
```

~Random Forest

```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(allowParallel = TRUE)

set.seed(seed)
fitRFDefault <- train(x, y, data = training1,
               method = "rf", metric = "Accuracy",
               trControl = fitControl)
paraOff()
end.time <- Sys.time()
time.takenRFDefault <- end.time - start.time #36.80987 minutes
fitRFDefault$results
```



```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)

set.seed(seed)
fitRF <- train(x, y, data=training1, 
               method="rf", 
               metric = "Accuracy",   
               trControl = fitControl,
               tuneGrid = expand.grid(mtry=round(sqrt(ncol(x)))))

paraOff()
end.time <- Sys.time()
time.takenRF <- end.time - start.time
fitRF$results
```

*Improve Results*
To improve the accuracy of the randomForest, I'll use the tuneRF function to optimize the mtry value.


```{r}
start.time <- Sys.time()
paraOn()

set.seed(seed)
optmtryRF2 <- tuneRF(x, y, 
                  stepFactor = 1.5, 
                  improve = 1e-4, ntreeTry = 500,
                  plot = TRUE)

paraOff()
end.time <- Sys.time()
time.takenRF2 <- end.time - start.time
optmtryRF2
```

The Out of Bag error as dependent on mtry seems to hold relatively constant between 6 and 9. As the rounded value of the square root of the number of columns comes out to 7, it doesn't appear that a changing the mtry value will return considerable change to the accuracy of the model.


Holding mtry constant, I will create a set of models with different ntree values to ascertain its ideal value.

```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = round(sqrt(ncol(x))))

#tune the algorithm for ntrees
fitList <- list()
for(ntree in c(300, 400, 500, 600, 700)){
        set.seed(seed)
        fitRF <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList[[key]] <- fitRF
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time
results <- resamples(fitList)
summary(results)
```


```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = round(sqrt(ncol(x))))

#tune the algorithm for ntrees
fitList2 <- list()
for(ntree in c(1000, 1500, 2000)){
        set.seed(seed)
        fitRF <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList[[key]] <- fitRF
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time

results2 <- resamples(fitList)
summary(results2)
```



```{r}
start.time <- Sys.time()
paraOn()

fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 3,
                           allowParallel = TRUE)
#keep mtry constant 
tuneGrid <- expand.grid(mtry = c(6:9))

#tune the algorithm for ntrees
fitList3 <- list()
for(ntree in c(700, 2000)){
        set.seed(seed)
        fitRF3 <- train(x, y, data = training1,
                       method = "rf", metric = "Accuracy", 
                       tuneGrid = tuneGrid, trControl = fitControl,
                       ntree = ntree)
        key <- toString(ntree)
        fitList3[[key]] <- fitRF3
}

paraOff()
end.time <- Sys.time()
time.takenRFtune <- end.time - start.time

results3 <- resamples(fitList3)
fitList3
```

